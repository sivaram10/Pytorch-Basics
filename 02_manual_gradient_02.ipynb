{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 38.5\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 0 w1= 1.09 w2= 0.75 b= 2.41 loss= 12.36\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 1 w1= 1.45 w2= 0.9 b= 2.5 loss= 0.09\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 2 w1= 1.27 w2= 0.85 b= 2.5 loss= 2.27\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 3 w1= 1.36 w2= 0.89 b= 2.54 loss= 0.34\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 4 w1= 1.31 w2= 0.88 b= 2.56 loss= 1.0\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 5 w1= 1.33 w2= 0.89 b= 2.59 loss= 0.58\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 6 w1= 1.32 w2= 0.89 b= 2.61 loss= 0.71\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 7 w1= 1.32 w2= 0.9 b= 2.64 loss= 0.6\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 8 w1= 1.32 w2= 0.9 b= 2.66 loss= 0.6\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 9 w1= 1.32 w2= 0.91 b= 2.68 loss= 0.56\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 10 w1= 1.31 w2= 0.91 b= 2.71 loss= 0.53\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 11 w1= 1.31 w2= 0.92 b= 2.73 loss= 0.51\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 12 w1= 1.31 w2= 0.92 b= 2.75 loss= 0.48\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 13 w1= 1.31 w2= 0.92 b= 2.77 loss= 0.46\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 14 w1= 1.31 w2= 0.93 b= 2.79 loss= 0.44\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 15 w1= 1.31 w2= 0.93 b= 2.81 loss= 0.42\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 16 w1= 1.3 w2= 0.94 b= 2.83 loss= 0.4\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 17 w1= 1.3 w2= 0.94 b= 2.85 loss= 0.38\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 18 w1= 1.3 w2= 0.94 b= 2.87 loss= 0.36\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 19 w1= 1.3 w2= 0.95 b= 2.89 loss= 0.34\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 20 w1= 1.3 w2= 0.95 b= 2.9 loss= 0.33\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 21 w1= 1.3 w2= 0.95 b= 2.92 loss= 0.31\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 22 w1= 1.29 w2= 0.95 b= 2.94 loss= 0.3\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 23 w1= 1.29 w2= 0.96 b= 2.96 loss= 0.29\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 24 w1= 1.29 w2= 0.96 b= 2.97 loss= 0.27\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 25 w1= 1.29 w2= 0.96 b= 2.99 loss= 0.26\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 26 w1= 1.29 w2= 0.96 b= 3.0 loss= 0.25\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 27 w1= 1.29 w2= 0.97 b= 3.02 loss= 0.24\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 28 w1= 1.29 w2= 0.97 b= 3.03 loss= 0.23\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 29 w1= 1.29 w2= 0.97 b= 3.05 loss= 0.22\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 30 w1= 1.28 w2= 0.97 b= 3.06 loss= 0.21\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 31 w1= 1.28 w2= 0.97 b= 3.08 loss= 0.2\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 32 w1= 1.28 w2= 0.98 b= 3.09 loss= 0.2\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 33 w1= 1.28 w2= 0.98 b= 3.11 loss= 0.19\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 34 w1= 1.28 w2= 0.98 b= 3.12 loss= 0.18\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 35 w1= 1.28 w2= 0.98 b= 3.13 loss= 0.17\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 36 w1= 1.28 w2= 0.98 b= 3.14 loss= 0.17\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 37 w1= 1.28 w2= 0.99 b= 3.16 loss= 0.16\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 38 w1= 1.28 w2= 0.99 b= 3.17 loss= 0.15\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 39 w1= 1.27 w2= 0.99 b= 3.18 loss= 0.15\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 40 w1= 1.27 w2= 0.99 b= 3.19 loss= 0.14\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 41 w1= 1.27 w2= 0.99 b= 3.21 loss= 0.14\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 42 w1= 1.27 w2= 0.99 b= 3.22 loss= 0.13\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 43 w1= 1.27 w2= 0.99 b= 3.23 loss= 0.13\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 44 w1= 1.27 w2= 1.0 b= 3.24 loss= 0.12\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 45 w1= 1.27 w2= 1.0 b= 3.25 loss= 0.12\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 46 w1= 1.27 w2= 1.0 b= 3.26 loss= 0.11\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 47 w1= 1.27 w2= 1.0 b= 3.27 loss= 0.11\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 48 w1= 1.27 w2= 1.0 b= 3.28 loss= 0.11\n",
      "\tgrad:  1.0 6.0\n",
      "\tgrad:  2.0 11.0\n",
      "\tgrad:  3.0 18.0\n",
      "progress: 49 w1= 1.27 w2= 1.0 b= 3.29 loss= 0.1\n",
      "predict (after training) 27.537636993030162\n"
     ]
    }
   ],
   "source": [
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [6.0, 11.0, 18.0]\n",
    "\n",
    "w1 = 2.0  # a random guess: random value #1\n",
    "w2 = 1.0  # a random guess: random value #2\n",
    "b = 2.5 # a random guess: random value #3\n",
    "\n",
    "# our model forward pass\n",
    "\n",
    "def forward(x):\n",
    "    return x * x * w1 + x * w2 + b\n",
    "\n",
    "\n",
    "# Loss function\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "\n",
    "# compute gradient\n",
    "def gradient(x, y):  # d_loss/d_w\n",
    "    dLdw1 = 4 * w1 * x * (w1 * x * x + w2 * x + b - y)\n",
    "    dLdw2 = 2 * x * (w1 * x * x + w2 * x + b - y)\n",
    "    dLdb = 2 * (w1 * x * x + w2 * x + b - y)\n",
    "    return (dLdw1, dLdw2, dLdb)\n",
    "\n",
    "# Before training\n",
    "print(\"predict (before training)\",  4, forward(4))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        grad = gradient(x_val, y_val)\n",
    "        w1 = w1 - 0.01 * grad[0]\n",
    "        w2 = w2 - 0.01 * grad[1]\n",
    "        b = b - 0.01 * grad[2]\n",
    "        print(\"\\tgrad: \", x_val, y_val)\n",
    "        l = loss(x_val, y_val)\n",
    "\n",
    "    print(\"progress:\", epoch, \"w1=\", round(w1, 2),\"w2=\", round(w2, 2),\"b=\", round(b, 2), \"loss=\", round(l, 2))\n",
    "\n",
    "# After training\n",
    "print(\"predict (after training)\", forward(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
